{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuiSSMartins/DTx-Project/blob/Faustino_Testes/DTx_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhdow6jv8LYI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gc #importing garbage collector\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_prices = pd.read_csv('sell_prices.csv')\n",
        "\n",
        "# função para reduzir a dimensão de um dataset\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n",
        "\n",
        "# diminuir o tamanho dos datasets\n",
        "#df_prices = reduce_mem_usage(df_prices)"
      ],
      "metadata": {
        "id": "nAh1SqMI2Mqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea575d5e-8373-440f-a5b7-ed85e09d72de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mem. usage decreased to 53.64 Mb (78.8% reduction)\n",
            "Mem. usage decreased to 42.86 Mb (37.5% reduction)\n",
            "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A análise exploratória dos dados e as suas coneções passam a ser feitas no KNIME!!!!!!"
      ],
      "metadata": {
        "id": "FwYed5_4SmVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregar dados (agora concatenados)"
      ],
      "metadata": {
        "id": "OVLZ5o1FSCtl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I11j27D4SeuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treino de Modelos"
      ],
      "metadata": {
        "id": "vk_uvrVySHU-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hzckxj48SBY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IGNORAR\n",
        "\n",
        "A partir daqui, tem apenas código auxiliar para ajudar a obter uma versão reduzida dos dados. Por isso, irá ficar tudo em comentário.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NzhduHH0HyJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "# (Prices preços) Reduzir os dados para apenas de uma loja\n",
        "\n",
        "df_prices = pd.read_csv('sell_prices.csv')\n",
        "\n",
        "csv_path = \"df_prices_Loja1.csv\"\n",
        "id_loja = \"CA_1\"\n",
        "coluna = \"store_id\"\n",
        "\n",
        "# Ler o arquivo CSV existente, se houver\n",
        "try:\n",
        "    df_existing = pd.read_csv(csv_path)\n",
        "except FileNotFoundError:\n",
        "    df_existing = pd.DataFrame()\n",
        "\n",
        "index = 0\n",
        "still_searching = True\n",
        "\n",
        "while still_searching:\n",
        "    actual_price = df_prices.iloc[index]\n",
        "    loja = actual_price[coluna]\n",
        "    if loja == id_loja:\n",
        "        print(index, end=' ')\n",
        "        # Adicionar a linha ao dataframe existente\n",
        "        df_existing = pd.concat([df_existing, actual_price], ignore_index=True)\n",
        "        index = index + 1\n",
        "        continue\n",
        "    still_searching = False\n",
        "\n",
        "# Salvar o dataframe resultante no arquivo CSV, adicionando ao final do arquivo\n",
        "df_existing.to_csv(csv_path, mode='a', index=False, header=not any(df_existing))\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "lJvfgibNNrKn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}